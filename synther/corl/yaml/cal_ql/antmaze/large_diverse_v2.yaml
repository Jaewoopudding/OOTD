alpha_multiplier: 1.0
backup_entropy: false
batch_size: 256
bc_steps: 0
buffer_size: 10000000
checkpoints_path: models
cql_alpha: 5.0
cql_alpha_online: 5.0
cql_clip_diff_max: .inf
cql_clip_diff_min: -200
cql_importance_sample: true
cql_lagrange: false
cql_max_target_backup: true
cql_n_actions: 10
cql_target_action_gap: 0.8
cql_temp: 1.0
device: cuda
discount: 0.99
env: antmaze-large-diverse-v2
eval_freq: 50000
load_model: ''
offline_iterations: 300000
online_iterations: 200000
mixing_ratio: 0.5
n_episodes: 100
normalize: true
normalize_reward: true
orthogonal_init: true
policy_lr: 0.0001
qf_lr: 0.0003
soft_target_update_rate: 0.005
target_update_period: 1
q_n_hidden_layers: 5
reward_scale: 1.0
reward_bias: -1.0
use_automatic_entropy_tuning: true
is_sparse_reward: true
